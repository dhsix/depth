import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from typing import Dict, Any, Optional

from .base_trainer import BaseTrainer
from utils.metrics import evaluate_depth_estimation

class DepthEstimationTrainer(BaseTrainer):
    """æ·±åº¦ä¼°è®¡ä¸“ç”¨è®­ç»ƒå™¨"""
    
    def __init__(self,
                 model: nn.Module,
                 train_loader: DataLoader,
                 val_loader: DataLoader,
                 optimizer: torch.optim.Optimizer,
                 scheduler: Optional[torch.optim.lr_scheduler._LRScheduler],
                 config: Dict[str, Any],
                 device: str = 'cuda'):
        
        super().__init__(model, train_loader, val_loader, optimizer, scheduler, config, device)
        
        # æ·±åº¦ä¼°è®¡ç‰¹å®šå‚æ•°
        self.use_mask = config.get('use_mask', True)
        self.compute_metrics_interval = config.get('compute_metrics_interval', 1)
        self._log_depth_estimation_setup()
    def _log_depth_estimation_setup(self):
        """è®°å½•æ·±åº¦ä¼°è®¡ç‰¹å®šçš„è®¾ç½®ä¿¡æ¯"""
        self.logger.log_info("ðŸ—ï¸ Depth Estimation Training Setup:")
        self.logger.log_info(f"   ðŸ“ Use Mask: {self.use_mask}")
        self.logger.log_info(f"   ðŸ“Š Metrics Computation Interval: {self.compute_metrics_interval}")
        self.logger.log_info(f"   ðŸŽ¯ Multi-scale Output: {getattr(self.model, 'use_multi_scale_output', False)}")
        
        if hasattr(self.model, 'loss_fn'):
            self.logger.log_info(f"   ðŸ“‰ Loss Function: {type(self.model.loss_fn).__name__}")
    def train_step(self, batch: Dict[str, torch.Tensor]) -> Dict[str, float]:
        """å•æ­¥è®­ç»ƒ"""
        
        images = batch['image']
        targets = batch['depth']
        masks = batch.get('mask') 
        
        # å‰å‘ä¼ æ’­
        if hasattr(self.model, 'forward'):
            # æ£€æŸ¥æ¨¡åž‹æ˜¯å¦æ”¯æŒå¤šå°ºåº¦è¾“å‡º
            if hasattr(self.model, 'use_multi_scale_output') and self.model.use_multi_scale_output:
                predictions = self.model(images, return_multi_scale=True)
            else:
                predictions = self.model(images)
        else:
            predictions = self.model(images)
        
        # è®¡ç®—æŸå¤±
        if hasattr(self.model, 'compute_loss'):
            loss_dict = self.model.compute_loss(predictions, targets, masks)
        else:
            # ä½¿ç”¨ç®€å•çš„MSEæŸå¤±ä½œä¸ºåŽå¤‡
            if isinstance(predictions, dict):
                # å¤šå°ºåº¦è¾“å‡ºï¼Œåªä½¿ç”¨æœ€é«˜åˆ†è¾¨çŽ‡è®¡ç®—æŸå¤±
                pred_tensor = predictions.get('scale_4', list(predictions.values())[-1])
            else:
                pred_tensor = predictions
            
            if masks is not None:
                valid_mask = masks.bool()
                loss = nn.functional.mse_loss(pred_tensor[valid_mask], targets[valid_mask])
            else:
                loss = nn.functional.mse_loss(pred_tensor, targets)
            
            loss_dict = {'total_loss': loss}
        
        # åå‘ä¼ æ’­
        total_loss = loss_dict['total_loss']
        total_loss.backward()
        
        # å‡†å¤‡è¿”å›žçš„æŒ‡æ ‡
        step_metrics = {}
        for key, value in loss_dict.items():
            if isinstance(value, torch.Tensor):
                step_metrics[key] = value.item()
            else:
                step_metrics[key] = value
        
        return step_metrics
    
    def val_step(self, batch: Dict[str, torch.Tensor]) -> Dict[str, float]:
        """å•æ­¥éªŒè¯"""
        
        images = batch['image']
        targets = batch['depth']
        masks = batch.get('mask') if self.use_mask else None
        
        # å‰å‘ä¼ æ’­
        if hasattr(self.model, 'predict'):
            if hasattr(self.model, 'use_multi_scale_output') and self.model.use_multi_scale_output:
                predictions = self.model.predict(images, return_multi_scale=True)
            else:
                predictions = self.model.predict(images)
        else:
            predictions = self.model(images)
        
        # è®¡ç®—æŸå¤±
        if hasattr(self.model, 'compute_loss'):
            loss_dict = self.model.compute_loss(predictions, targets, masks)
        else:
            # åŽå¤‡æŸå¤±è®¡ç®—
            if isinstance(predictions, dict):
                pred_tensor = predictions.get('scale_4', list(predictions.values())[-1])
            else:
                pred_tensor = predictions
            
            if masks is not None:
                valid_mask = masks.bool()
                loss = nn.functional.mse_loss(pred_tensor[valid_mask], targets[valid_mask])
            else:
                loss = nn.functional.mse_loss(pred_tensor, targets)
            
            loss_dict = {'total_loss': loss}
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        step_metrics = {}
        for key, value in loss_dict.items():
            if isinstance(value, torch.Tensor):
                step_metrics[key] = value.item()
            else:
                step_metrics[key] = value
        
        # è®¡ç®—æ·±åº¦ä¼°è®¡æŒ‡æ ‡ï¼ˆæ¯éš”ä¸€å®šé—´éš”è®¡ç®—ï¼Œå› ä¸ºæ¯”è¾ƒè€—æ—¶ï¼‰
        if self.current_epoch % self.compute_metrics_interval == 0:
            if isinstance(predictions, dict):
                pred_for_metrics = predictions.get('scale_4', list(predictions.values())[-1])
            else:
                pred_for_metrics = predictions
            
            try:
                depth_metrics = evaluate_depth_estimation(pred_for_metrics, targets, masks)
                step_metrics.update(depth_metrics)
                # æ·»åŠ è¿™äº›é¢å¤–ç»Ÿè®¡ä¿¡æ¯
                step_metrics['valid_pixels'] = masks.sum().item() if masks is not None else targets.numel()
                step_metrics['total_pixels'] = targets.numel()
                step_metrics['height_range'] = (targets.max() - targets.min()).item()
                step_metrics['mean_height'] = targets.mean().item()
            except Exception as e:
                # self.logger.log_info(f"Warning: Failed to compute depth metrics: {e}")
                self.logger.log_warning(f"Failed to compute depth metrics: {e}")
        
        return step_metrics

class MultiScaleDepthTrainer(DepthEstimationTrainer):
    """å¤šå°ºåº¦æ·±åº¦ä¼°è®¡è®­ç»ƒå™¨"""
    
    def __init__(self,
                 model: nn.Module,
                 train_loader: DataLoader,
                 val_loader: DataLoader,
                 optimizer: torch.optim.Optimizer,
                 scheduler: Optional[torch.optim.lr_scheduler._LRScheduler],
                 config: Dict[str, Any],
                 device: str = 'cuda'):
        
        super().__init__(model, train_loader, val_loader, optimizer, scheduler, config, device)
        
        # å¤šå°ºåº¦ç‰¹å®šå‚æ•°
        self.scale_weights = config.get('scale_weights', [1.0, 1.0, 1.0, 1.0])
        self.log_scale_losses = config.get('log_scale_losses', True)
        # âœ… æ·»åŠ è¿™éƒ¨åˆ†
        self.logger.log_info("ðŸ”„ Multi-Scale Configuration:")
        self.logger.log_info(f"   âš–ï¸  Scale Weights: {self.scale_weights}")
        self.logger.log_info(f"   ðŸ“Š Log Scale Losses: {self.log_scale_losses}")
    
    def train_step(self, batch: Dict[str, torch.Tensor]) -> Dict[str, float]:
        """å¤šå°ºåº¦è®­ç»ƒæ­¥éª¤"""
        
        images = batch['image']
        targets = batch['depth']
        masks = batch.get('mask') if self.use_mask else None
        
        # å¼ºåˆ¶ä½¿ç”¨å¤šå°ºåº¦è¾“å‡º
        predictions = self.model(images, return_multi_scale=True)
        
        # è®¡ç®—å¤šå°ºåº¦æŸå¤±
        loss_dict = self.model.compute_loss(predictions, targets, masks)
        
        # åå‘ä¼ æ’­
        total_loss = loss_dict['total_loss']
        total_loss.backward()
        
        # å‡†å¤‡è¿”å›žçš„æŒ‡æ ‡
        step_metrics = {}
        for key, value in loss_dict.items():
            if isinstance(value, torch.Tensor):
                step_metrics[key] = value.item()
            else:
                step_metrics[key] = value
        
        # è®°å½•å„å°ºåº¦çš„æŸå¤±ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        if self.log_scale_losses and isinstance(predictions, dict):
            for scale_key, scale_pred in predictions.items():
                try:
                    # è®¡ç®—å•å°ºåº¦æŸå¤±ç”¨äºŽç›‘æŽ§
                    target_resized = torch.nn.functional.interpolate(
                        targets.unsqueeze(1),
                        size=scale_pred.shape[-2:],
                        mode='bilinear',
                        align_corners=True
                    ).squeeze(1)
                    
                    scale_loss = nn.functional.mse_loss(scale_pred, target_resized)
                    step_metrics[f'loss_{scale_key}'] = scale_loss.item()
                except Exception as e:
                    self.logger.log_warning(f"Failed to compute scale loss for {scale_key}: {e}")
                # except:
                #     pass
        
        return step_metrics
    
    def val_step(self, batch: Dict[str, torch.Tensor]) -> Dict[str, float]:
        """å¤šå°ºåº¦éªŒè¯æ­¥éª¤"""
        
        images = batch['image']
        targets = batch['depth']
        masks = batch.get('mask') if self.use_mask else None
        
        # èŽ·å–å¤šå°ºåº¦é¢„æµ‹
        predictions = self.model.predict(images, return_multi_scale=True)
        
        # è®¡ç®—æŸå¤±
        loss_dict = self.model.compute_loss(predictions, targets, masks)
        
        step_metrics = {}
        for key, value in loss_dict.items():
            if isinstance(value, torch.Tensor):
                step_metrics[key] = value.item()
            else:
                step_metrics[key] = value
        
        # è®¡ç®—æœ€é«˜åˆ†è¾¨çŽ‡çš„æ·±åº¦æŒ‡æ ‡
        if self.current_epoch % self.compute_metrics_interval == 0:
            pred_for_metrics = predictions.get('scale_4', list(predictions.values())[-1])
            
            try:
                depth_metrics = evaluate_depth_estimation(pred_for_metrics, targets, masks)
                step_metrics.update(depth_metrics)
            except Exception as e:
                # self.logger.log_info(f"Warning: Failed to compute depth metrics: {e}")
                self.logger.log_warning(f"Failed to compute depth metrics: {e}")
        
        # è®°å½•å„å°ºåº¦æŸå¤±
        if self.log_scale_losses:
            for scale_key, scale_pred in predictions.items():
                try:
                    target_resized = torch.nn.functional.interpolate(
                        targets.unsqueeze(1),
                        size=scale_pred.shape[-2:],
                        mode='bilinear',
                        align_corners=True
                    ).squeeze(1)
                    
                    scale_loss = nn.functional.mse_loss(scale_pred, target_resized)
                    step_metrics[f'val_loss_{scale_key}'] = scale_loss.item()
                except Exception as e:
                    self.logger.log_warning(f"Failed to compute scale loss for {scale_key}: {e}")
                # except:
                #     pass

        
        return step_metrics

def create_trainer(model: nn.Module,
                  train_loader: DataLoader,
                  val_loader: DataLoader,
                  optimizer: torch.optim.Optimizer,
                  scheduler: Optional[torch.optim.lr_scheduler._LRScheduler],
                  config: Dict[str, Any],
                  device: str = 'cuda') -> BaseTrainer:
    """è®­ç»ƒå™¨å·¥åŽ‚å‡½æ•°"""
    
    trainer_type = config.get('trainer_type', 'depth')
    
    if trainer_type == 'multi_scale_depth':
        return MultiScaleDepthTrainer(
            model, train_loader, val_loader, optimizer, scheduler, config, device
        )
    elif trainer_type == 'depth':
        return DepthEstimationTrainer(
            model, train_loader, val_loader, optimizer, scheduler, config, device
        )
    else:
        raise ValueError(f"Unknown trainer type: {trainer_type}")